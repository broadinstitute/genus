{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# KL between Bernoulli Posterior and DPP prior"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook demonstrates how to use importance sampling to compute the KL between a Bernoulli Posterior and DPP prior."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install -U neptune-notebooks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import numpy\n",
    "from genus.util_ml import Grid_DPP, compute_logp_bernoulli, compute_entropy_bernoulli\n",
    "from genus.util_vis import show_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class simplified_model(torch.nn.Module):\n",
    "    def __init__(self,\n",
    "                 length_scale: float=5.0,\n",
    "                 weight: float=0.2,\n",
    "                 mc_temperatures: list=[1.0,2.0,3.0],\n",
    "                 n_mc_samples_for_temperature: int=100,\n",
    "                 importance_sampling: bool=True):\n",
    "        super().__init__()\n",
    "        B, W, H = 8, 10, 10\n",
    "        self.length_scale = length_scale\n",
    "        self.weight = weight\n",
    "        self.importance_sampling = importance_sampling\n",
    "        self.mc_temperatures = torch.tensor(mc_temperatures, dtype=torch.float, requires_grad=False)\n",
    "        self.n_mc_samples_for_temperature = n_mc_samples_for_temperature\n",
    "        self.grid_dpp = Grid_DPP(length_scale=length_scale,\n",
    "                                 weight=weight,\n",
    "                                 learnable_params=False)\n",
    "        self.logit = torch.nn.Parameter(data=torch.randn((B,1,W,H), dtype=torch.float), requires_grad=True)\n",
    "        \n",
    "    def sample_dpp_prior(self):\n",
    "        return self.grid_dpp.sample(size=self.logit.size())\n",
    "        \n",
    "    \n",
    "    def forward(self):\n",
    "\n",
    "        # This term can be compute analytically\n",
    "        entropy_ber = compute_entropy_bernoulli(logit=self.logit).sum(dim=(-1, -2, -3)).mean()\n",
    "            \n",
    "            \n",
    "        if self.importance_sampling:\n",
    "            # Use a Bernoulli distribution at higher temperature to evaluate the KL divergence\n",
    "            temp_block = self.mc_temperatures.view(1,-1,1,1,1,1).detach()\n",
    "            logit_expanded_ntb1wh = self.logit.expand([self.n_mc_samples_for_temperature,\n",
    "                                                              self.mc_temperatures.shape[0],-1,-1,-1,-1]) / temp_block\n",
    "            prob_expanded_ntb1wh = torch.sigmoid(logit_expanded_ntb1wh)\n",
    "            c_mcsamples_ntb1wh = (torch.rand_like(prob_expanded_ntb1wh) < prob_expanded_ntb1wh)\n",
    "            logp_ber_ntb = compute_logp_bernoulli(c=c_mcsamples_ntb1wh, logit=self.logit).sum(dim=(-1, -2, -3))\n",
    "            with torch.no_grad():\n",
    "                logp_ber_importance_ntb = compute_logp_bernoulli(c=c_mcsamples_ntb1wh,\n",
    "                                                                 logit=logit_expanded_ntb1wh).sum(dim=(-1, -2, -3))\n",
    "                importance_weight_ntb = (logp_ber_ntb - logp_ber_importance_ntb).exp()\n",
    "                logp_dpp_ntb = self.grid_dpp.log_prob(value=c_mcsamples_ntb1wh.squeeze(-3).detach())\n",
    "                baseline_tb = logp_dpp_ntb.mean(dim=0)  # average w.r.t. the samples taken and the same temperature\n",
    "                d_ntb = (logp_dpp_ntb - baseline_tb)\n",
    "            reinforce_ber = (importance_weight_ntb * logp_ber_ntb * d_ntb.detach()).mean()\n",
    "            logit_kl_av = - entropy_ber - reinforce_ber\n",
    "            \n",
    "        else: \n",
    "            # Use the Bernoulli distribution at Temperature = 1 to evaluate the KL divergence\n",
    "            prob_b1wh = torch.sigmoid(self.logit)\n",
    "            prob_expanded_ntb1wh = prob_b1wh.expand([self.n_mc_samples_for_temperature,\n",
    "                                                     self.mc_temperatures.shape[0],-1,-1,-1,-1])  # keep: batch,ch,w,h\n",
    "            c_mcsamples_ntb1wh = (torch.rand_like(prob_expanded_ntb1wh) < prob_expanded_ntb1wh)\n",
    "            logp_ber_ntb = compute_logp_bernoulli(c=c_mcsamples_ntb1wh.detach(), logit=self.logit).sum(dim=(-1, -2, -3))\n",
    "            with torch.no_grad():\n",
    "                logp_dpp_ntb = self.grid_dpp.log_prob(value=c_mcsamples_ntb1wh.squeeze(-3).detach())\n",
    "                baseline_tb = logp_dpp_ntb.mean(dim=0) # average w.r.t. the samples taken and the same temperature\n",
    "                d_ntb = (logp_dpp_ntb - baseline_tb)\n",
    "            reinforce_ber = (logp_ber_ntb * d_ntb.detach()).mean()\n",
    "            logit_kl_av = - entropy_ber - reinforce_ber\n",
    "            \n",
    "        loss = logit_kl_av\n",
    "        c_sample = (torch.rand_like(self.logit) < torch.sigmoid(self.logit))\n",
    "        return loss, c_sample, reinforce_ber"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://ui.neptune.ai/dalessioluca/genus-new/e/GEN1-242\n"
     ]
    }
   ],
   "source": [
    "import neptune.new as neptune\n",
    "\n",
    "exp = neptune.init(project='dalessioluca/genus-new')\n",
    "                                    \n",
    "model = simplified_model(length_scale=5.0, \n",
    "                         weight=0.2, \n",
    "                         mc_temperatures=[1.0],\n",
    "                         importance_sampling=False,\n",
    "                         n_mc_samples_for_temperature=10)\n",
    "optimizer = torch.optim.Adam([{'params': model.parameters(), 'lr': 0.001}])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Log info about the simulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1.])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.mc_temperatures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp[\"config/length_scale\"].log(model.length_scale)\n",
    "exp[\"config/weight\"].log(model.weight)\n",
    "exp[\"config/importance_sampling\"].log(model.importance_sampling)\n",
    "exp[\"config/mc_temperatures\"].log(model.mc_temperatures)\n",
    "exp[\"config/n_mc_samples_for_temperature\"].log(model.n_mc_samples_for_temperature)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Log info about the prior"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c_grid = model.sample_dpp_prior()\n",
    "n_av = model.grid_dpp.n_mean\n",
    "n_std = model.grid_dpp.n_stddev\n",
    "\n",
    "exp[\"prior/n_cell_av\"].log(n_av)\n",
    "exp[\"prior/n_cell_p1sigma\"].log(n_av+n_std)\n",
    "exp[\"prior/n_cell_m1sigma\"].log(n_av-n_std)\n",
    "\n",
    "show_batch(model.logit, pad_value=1.0, n_padding=2, normalize_range=(-3.0, 3.0), \n",
    "               normalize=True, experiment=exp, neptune_name=\"prior/logit_raw\", title=\"PRIOR\")\n",
    "show_batch(c_grid.float(), pad_value=0.5, n_padding=2, experiment=exp, neptune_name=\"prior/c_grid\", title=\"PRIOR\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 tensor(-43.4818, grad_fn=<SubBackward0>)\n",
      "100 tensor(-61.1092, grad_fn=<SubBackward0>)\n",
      "200 tensor(-70.0420, grad_fn=<SubBackward0>)\n",
      "300 tensor(-82.0780, grad_fn=<SubBackward0>)\n",
      "400 tensor(-96.4940, grad_fn=<SubBackward0>)\n",
      "500 tensor(-64.0989, grad_fn=<SubBackward0>)\n",
      "600 tensor(-77.0422, grad_fn=<SubBackward0>)\n",
      "700 tensor(-110.2672, grad_fn=<SubBackward0>)\n",
      "800 tensor(-116.3999, grad_fn=<SubBackward0>)\n",
      "900 tensor(-101.9460, grad_fn=<SubBackward0>)\n",
      "1000 tensor(-120.1823, grad_fn=<SubBackward0>)\n",
      "1100 tensor(-97.9827, grad_fn=<SubBackward0>)\n",
      "1200 tensor(-110.2559, grad_fn=<SubBackward0>)\n",
      "1300 tensor(-114.5938, grad_fn=<SubBackward0>)\n",
      "1400 tensor(-132.9603, grad_fn=<SubBackward0>)\n",
      "1500 tensor(-111.7741, grad_fn=<SubBackward0>)\n",
      "1600 tensor(-109.9716, grad_fn=<SubBackward0>)\n",
      "1700 tensor(-119.8787, grad_fn=<SubBackward0>)\n",
      "1800 tensor(-149.7139, grad_fn=<SubBackward0>)\n",
      "1900 tensor(-107.3579, grad_fn=<SubBackward0>)\n",
      "2000 tensor(-128.1720, grad_fn=<SubBackward0>)\n",
      "2100 tensor(-137.0563, grad_fn=<SubBackward0>)\n",
      "2200 tensor(-111.1198, grad_fn=<SubBackward0>)\n",
      "2300 tensor(-131.3527, grad_fn=<SubBackward0>)\n",
      "2400 tensor(-122.6524, grad_fn=<SubBackward0>)\n",
      "2500 tensor(-144.1656, grad_fn=<SubBackward0>)\n",
      "2600 tensor(-115.3373, grad_fn=<SubBackward0>)\n",
      "2700 tensor(-158.9114, grad_fn=<SubBackward0>)\n",
      "2800 tensor(-131.5786, grad_fn=<SubBackward0>)\n",
      "2900 tensor(-114.1066, grad_fn=<SubBackward0>)\n",
      "3000 tensor(-197.0181, grad_fn=<SubBackward0>)\n",
      "3100 tensor(-156.1237, grad_fn=<SubBackward0>)\n",
      "3200 tensor(-143.7691, grad_fn=<SubBackward0>)\n",
      "3300 tensor(-129.4243, grad_fn=<SubBackward0>)\n",
      "3400 tensor(-148.0112, grad_fn=<SubBackward0>)\n",
      "3500 tensor(-181.5354, grad_fn=<SubBackward0>)\n",
      "3600 tensor(-141.2165, grad_fn=<SubBackward0>)\n",
      "3700 tensor(-143.9387, grad_fn=<SubBackward0>)\n",
      "3800 tensor(-185.0672, grad_fn=<SubBackward0>)\n",
      "3900 tensor(-145.8294, grad_fn=<SubBackward0>)\n",
      "4000 tensor(-145.3961, grad_fn=<SubBackward0>)\n",
      "4100 tensor(-158.4290, grad_fn=<SubBackward0>)\n",
      "4200 tensor(-152.4408, grad_fn=<SubBackward0>)\n",
      "4300 tensor(-147.2899, grad_fn=<SubBackward0>)\n",
      "4400 tensor(-203.8213, grad_fn=<SubBackward0>)\n",
      "4500 tensor(-184.1276, grad_fn=<SubBackward0>)\n",
      "4600 tensor(-156.4714, grad_fn=<SubBackward0>)\n",
      "4700 tensor(-153.6738, grad_fn=<SubBackward0>)\n",
      "4800 tensor(-172.2437, grad_fn=<SubBackward0>)\n",
      "4900 tensor(-195.1409, grad_fn=<SubBackward0>)\n",
      "5000 tensor(-172.0592, grad_fn=<SubBackward0>)\n",
      "5100 tensor(-193.5246, grad_fn=<SubBackward0>)\n",
      "5200 tensor(-161.4200, grad_fn=<SubBackward0>)\n",
      "5300 tensor(-174.7703, grad_fn=<SubBackward0>)\n",
      "5400 tensor(-167.8806, grad_fn=<SubBackward0>)\n",
      "5500 tensor(-147.0084, grad_fn=<SubBackward0>)\n",
      "5600 tensor(-186.1806, grad_fn=<SubBackward0>)\n",
      "5700 tensor(-170.2461, grad_fn=<SubBackward0>)\n",
      "5800 tensor(-173.7874, grad_fn=<SubBackward0>)\n",
      "5900 tensor(-231.5770, grad_fn=<SubBackward0>)\n",
      "6000 tensor(-158.6732, grad_fn=<SubBackward0>)\n",
      "6100 tensor(-165.3167, grad_fn=<SubBackward0>)\n",
      "6200 tensor(-141.6085, grad_fn=<SubBackward0>)\n",
      "6300 tensor(-160.4629, grad_fn=<SubBackward0>)\n",
      "6400 tensor(-207.6812, grad_fn=<SubBackward0>)\n",
      "6500 tensor(-157.0511, grad_fn=<SubBackward0>)\n",
      "6600 tensor(-176.5328, grad_fn=<SubBackward0>)\n",
      "6700 tensor(-144.4787, grad_fn=<SubBackward0>)\n",
      "6800 tensor(-164.7792, grad_fn=<SubBackward0>)\n",
      "6900 tensor(-179.3410, grad_fn=<SubBackward0>)\n",
      "7000 tensor(-194.2566, grad_fn=<SubBackward0>)\n",
      "7100 tensor(-166.2072, grad_fn=<SubBackward0>)\n",
      "7200 tensor(-163.9840, grad_fn=<SubBackward0>)\n",
      "7300 tensor(-178.9455, grad_fn=<SubBackward0>)\n",
      "7400 tensor(-137.8821, grad_fn=<SubBackward0>)\n",
      "7500 tensor(-189.6002, grad_fn=<SubBackward0>)\n",
      "7600 tensor(-160.9999, grad_fn=<SubBackward0>)\n",
      "7700 tensor(-184.5315, grad_fn=<SubBackward0>)\n",
      "7800 tensor(-241.3600, grad_fn=<SubBackward0>)\n",
      "7900 tensor(-184.3937, grad_fn=<SubBackward0>)\n",
      "8000 tensor(-172.5901, grad_fn=<SubBackward0>)\n",
      "8100 tensor(-151.3113, grad_fn=<SubBackward0>)\n",
      "8200 tensor(-181.0365, grad_fn=<SubBackward0>)\n",
      "8300 tensor(-176.4880, grad_fn=<SubBackward0>)\n",
      "8400 tensor(-147.9740, grad_fn=<SubBackward0>)\n",
      "8500 tensor(-167.7791, grad_fn=<SubBackward0>)\n",
      "8600 tensor(-171.7702, grad_fn=<SubBackward0>)\n",
      "8700 tensor(-138.4066, grad_fn=<SubBackward0>)\n",
      "8800 tensor(-146.5909, grad_fn=<SubBackward0>)\n",
      "8900 tensor(-157.7525, grad_fn=<SubBackward0>)\n",
      "9000 tensor(-167.0325, grad_fn=<SubBackward0>)\n",
      "9100 tensor(-145.7287, grad_fn=<SubBackward0>)\n",
      "9200 tensor(-117.5010, grad_fn=<SubBackward0>)\n",
      "9300 tensor(-206.2245, grad_fn=<SubBackward0>)\n",
      "9400 tensor(-165.4309, grad_fn=<SubBackward0>)\n",
      "9500 tensor(-203.3687, grad_fn=<SubBackward0>)\n",
      "9600 tensor(-129.1154, grad_fn=<SubBackward0>)\n",
      "9700 tensor(-147.1834, grad_fn=<SubBackward0>)\n",
      "9800 tensor(-135.0746, grad_fn=<SubBackward0>)\n",
      "9900 tensor(-170.7563, grad_fn=<SubBackward0>)\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(10000):\n",
    "    loss, c_grid, delta = model.forward()\n",
    "    \n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()  # do back_prop and compute all the gradients\n",
    "    optimizer.step()  # update the parameters    \n",
    "    \n",
    "    if epoch % 100 == 0:\n",
    "        n_cell_b = c_grid.sum(dim=(-1,-2,-3)).float()\n",
    "        n_cell_std, n_cell_av = torch.std_mean(n_cell_b)\n",
    "        n_cell_p1sigma = (n_cell_av+n_cell_std).detach().item()\n",
    "        n_cell_m1sigma = (n_cell_av-n_cell_std).detach().item()\n",
    "        \n",
    "        n_cell_min = n_cell_b.min().detach().item()\n",
    "        n_cell_max = n_cell_b.max().detach().item()\n",
    "        exp[\"posterior/n_cell_av\"].log(n_cell_av)\n",
    "        exp[\"posterior/n_cell_min\"].log(n_cell_min)\n",
    "        exp[\"posterior/n_cell_max\"].log(n_cell_max)        \n",
    "        exp[\"posterior/n_cell_p1sigma\"].log(n_cell_p1sigma)\n",
    "        exp[\"posterior/n_cell_m1sigma\"].log(n_cell_m1sigma)\n",
    "\n",
    "        logit_min = torch.min(model.logit).item()\n",
    "        logit_mean = torch.mean(model.logit).item()\n",
    "        logit_max = torch.max(model.logit).item()\n",
    "        exp[\"posterior/logit_min\"].log(logit_min)\n",
    "        exp[\"posterior/logit_mean\"].log(logit_mean)\n",
    "        exp[\"posterior/logit_max\"].log(logit_max)\n",
    "        \n",
    "        exp[\"delta\"].log(delta.detach().item())\n",
    "        \n",
    "        show_batch(c_grid.float(), pad_value=0.5, n_padding=2, experiment=exp, neptune_name=\"posterior/c_grid\", \n",
    "                   title=\"epoch=\"+str(epoch))\n",
    "        show_batch(model.logit, pad_value=1.0, n_padding=2, normalize_range=(-3.0, 3.0), \n",
    "               normalize=True, experiment=exp, neptune_name=\"posterior/logit_raw\", title=\"epoch=\"+str(epoch))\n",
    "        \n",
    "        print(epoch, loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "neptune": {
   "notebookId": "ea58cca6-5f9c-4037-8151-a3c4003e7b30"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
