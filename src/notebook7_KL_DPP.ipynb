{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Determinental Point Process (DPP)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook demonstrates how to draw random samples from FiniteDPP process defined by a square exponential similarity kernel with different values of lenght_scale and prefactor. \n",
    "\n",
    "For each combination of lenght_scale and prefactor, we draw a random sample and compute the average and the standard deviation in the number of objects."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install -U neptune-notebooks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import numpy\n",
    "from genus.util_ml import Grid_DPP, compute_logp_bernoulli, compute_entropy_bernoulli\n",
    "from genus.util_vis import show_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "class simplified_model(torch.nn.Module):\n",
    "    def __init__(self,\n",
    "                 length_scale: float,\n",
    "                 weight: float):\n",
    "        super().__init__()\n",
    "        B, W, H = 8, 10, 10\n",
    "        self.n_mc_samples = 100\n",
    "        self.grid_dpp = Grid_DPP(length_scale=length_scale,\n",
    "                                 weight=weight,\n",
    "                                 learnable_params=False)\n",
    "        \n",
    "        self.logit = torch.nn.Parameter(data=torch.randn((B,1,W,H), dtype=torch.float), requires_grad=True)\n",
    "    \n",
    "    def forward(self, generate_synthetic_data=False, method=2):\n",
    "        prob = torch.sigmoid(self.logit)\n",
    "\n",
    "        if generate_synthetic_data:\n",
    "            # sample from dpp prior\n",
    "            c_grid_before_nms_mcsamples = self.grid_dpp.sample(size=prob.size()).unsqueeze(dim=0)\n",
    "        else:\n",
    "            prob_expanded = prob.expand([self.n_mc_samples] + list(prob.shape))\n",
    "            c_grid_before_nms_mcsamples = (torch.rand_like(prob_expanded) < prob_expanded)\n",
    "        \n",
    "        if method == 1:\n",
    "            logp_ber_before_nms_mb = compute_logp_bernoulli(c=c_grid_before_nms_mcsamples.detach(),\n",
    "                                                            logit=self.logit).sum(dim=(-1, -2, -3))\n",
    "            logp_dpp_before_nms_mb = self.grid_dpp.log_prob(value=c_grid_before_nms_mcsamples.squeeze(-3).detach())\n",
    "            f = logp_ber_before_nms_mb - logp_dpp_before_nms_mb\n",
    "            baseline = f.mean(dim=-2).detach()\n",
    "            delta = (f-baseline)\n",
    "            logit_kl_av = torch.mean(logp_ber_before_nms_mb * delta.detach() + delta)\n",
    "        else:\n",
    "            entropy_b = compute_entropy_bernoulli(logit=self.logit).sum(dim=(-1, -2, -3))\n",
    "            logp_ber_before_nms_mb = compute_logp_bernoulli(c=c_grid_before_nms_mcsamples.detach(),\n",
    "                                                            logit=self.logit).sum(dim=(-1, -2, -3))\n",
    "            logp_dpp_before_nms_mb = self.grid_dpp.log_prob(value=c_grid_before_nms_mcsamples.squeeze(-3).detach())\n",
    "            baseline = logp_dpp_before_nms_mb.mean(dim=-2).detach()\n",
    "            delta = (logp_dpp_before_nms_mb - baseline)\n",
    "            logit_kl_av = (-entropy_b - logp_ber_before_nms_mb * delta.detach()).mean()\n",
    "        loss = logit_kl_av\n",
    "        return loss, c_grid_before_nms_mcsamples, delta.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://ui.neptune.ai/dalessioluca/genus-new/e/GEN1-70\n"
     ]
    }
   ],
   "source": [
    "import neptune.new as neptune\n",
    "\n",
    "exp = neptune.init(project='dalessioluca/genus-new')\n",
    "                                    \n",
    "model = simplified_model(length_scale=5.0, weight=0.2)\n",
    "optimizer = torch.optim.Adam([{'params': model.parameters(), 'lr': 0.001}])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "too many values to unpack (expected 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-39-8369ed9c3d3e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mc_grid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgenerate_synthetic_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m: too many values to unpack (expected 2)"
     ]
    }
   ],
   "source": [
    "loss, c_grid = model.forward(generate_synthetic_data=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_batch(c_grid[0].float(), pad_value=0.5, n_padding=2, experiment=exp, neptune_name=\"c_grid_prior\", title=\"PRIOR\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 tensor(-69.0482, grad_fn=<MeanBackward0>)\n",
      "100 tensor(-68.9649, grad_fn=<MeanBackward0>)\n",
      "200 tensor(-81.2637, grad_fn=<MeanBackward0>)\n",
      "300 tensor(-91.8169, grad_fn=<MeanBackward0>)\n",
      "400 tensor(-83.3469, grad_fn=<MeanBackward0>)\n",
      "500 tensor(-108.2815, grad_fn=<MeanBackward0>)\n",
      "600 tensor(-116.2634, grad_fn=<MeanBackward0>)\n",
      "700 tensor(-122.3692, grad_fn=<MeanBackward0>)\n",
      "800 tensor(-121.8282, grad_fn=<MeanBackward0>)\n",
      "900 tensor(-128.8625, grad_fn=<MeanBackward0>)\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(1000):\n",
    "    loss, c_grid, delta = model.forward()\n",
    "    \n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()  # do back_prop and compute all the gradients\n",
    "    optimizer.step()  # update the parameters    \n",
    "    \n",
    "    if epoch % 100 == 0:\n",
    "        n_cell = c_grid.sum(dim=(-1,-2,-3)).float().mean().detach().item()\n",
    "        exp[\"n_cell\"].log(n_cell)\n",
    "        logit_min = torch.min(model.logit).item()\n",
    "        logit_mean = torch.mean(model.logit).item()\n",
    "        logit_max = torch.max(model.logit).item()\n",
    "        exp[\"logit/min\"].log(logit_min)\n",
    "        exp[\"logit/mean\"].log(logit_mean)\n",
    "        exp[\"logit/max\"].log(logit_max)\n",
    "        exp[\"delta\"].log(delta.detach().item())\n",
    "        \n",
    "        show_batch(c_grid[0].float(), pad_value=0.5, n_padding=2, experiment=exp, neptune_name=\"c_grid\", \n",
    "                   title=\"epoch=\"+str(epoch))\n",
    "        show_batch(model.logit, pad_value=1.0, n_padding=2, normalize_range=(-3.0, 3.0), \n",
    "               normalize=True, experiment=exp, neptune_name=\"logit/raw\", title=\"epoch=\"+str(epoch))\n",
    "        \n",
    "        print(epoch, loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c_grid[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_batch(c_grid[0].float(), pad_value=0.5, n_padding=2, experiment=exp, neptune_name=\"c_grid\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "neptune": {
   "notebookId": "ea58cca6-5f9c-4037-8151-a3c4003e7b30"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
